{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevinlo937/objects_story/blob/main/cv_MultipleObjectDection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k3FFkJ-w1_B",
        "outputId": "6476d9be-f746-4e6c-af69-2f4bc4ddaf8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.118-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.118-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.118 ultralytics-thop-2.0.14\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.61-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.1.31)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.57.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n",
            "Downloading roboflow-1.1.61-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.61\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# 安裝 Ultralytics YOLOv8\n",
        "!pip install ultralytics\n",
        "\n",
        "# 安裝 Roboflow 套件（用於資料集下載）\n",
        "!pip install roboflow\n",
        "\n",
        "# 安裝其他依賴套件\n",
        "!pip install opencv-python numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXjz3PwNXQOT",
        "outputId": "66f197d3-749f-4e9d-a10a-efdc1566e907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# 檢查 CUDA 是否可用\n",
        "!python -c \"import torch; print(torch.cuda.is_available())\"\n",
        "\n",
        "# 檢查可用的 GPU 數量\n",
        "!python -c \"import torch; print(torch.cuda.device_count())\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rok3It0N_HRE",
        "outputId": "9e620e2f-f981-4484-95d3-ca0f86b9cd39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.61-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.1.31)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.57.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n",
            "Downloading roboflow-1.1.61-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.61\n"
          ]
        }
      ],
      "source": [
        "# 安裝 Roboflow 套件（用於資料集下載）\n",
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaUfQsdE-7W8",
        "outputId": "62d7bd45-31fd-429c-fa6e-c62fbff11037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Exporting format yolov8 in progress : 85.0%\n",
            "Version export complete for yolov8 format\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in package-detection-1 to yolov8:: 100%|██████████| 4091/4091 [00:00<00:00, 12673.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to package-detection-1 in yolov8:: 100%|██████████| 382/382 [00:00<00:00, 10676.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rloading Roboflow workspace...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rloading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in package-at-front-door-1 to yolov8:: 100%|██████████| 11238/11238 [00:00<00:00, 26736.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to package-at-front-door-1 in yolov8:: 100%|██████████| 876/876 [00:00<00:00, 10076.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rloading Roboflow workspace...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rloading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in BagDetector-1 to yolov8:: 100%|██████████| 12315/12315 [00:00<00:00, 24909.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to BagDetector-1 in yolov8:: 100%|██████████| 732/732 [00:00<00:00, 9704.96it/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import roboflow\n",
        "\n",
        "# Set your Roboflow API key as an environment variable\n",
        "os.environ[\"ROBOFLOW_API_KEY\"] = \"NKaOxmYYLFRPaf6w0uF6\" # Replace with your actual API key\n",
        "\n",
        "rf = roboflow.Roboflow(api_key=os.environ.get(\"ROBOFLOW_API_KEY\"))\n",
        "\n",
        "# The rest of your code remains the same...\n",
        "# Download the package dataset, 276 views , 18 downloads, mAP@50=99.5% , Precision=100%, Recall=99.2%\n",
        "# package_detection_dataset = rf.workspace(\"packagedetection\").project(\"package-detection-kt9ut\").version(2).download(\"yolov8\")\n",
        "\n",
        "# Download the Package at Front Door dataset, 2022-11-30, 1.4k views , 85 downloads , mAP@50=96.4%, Precision=95.7%, Recall=88.2%\n",
        "package_dataset = rf.workspace(\"package-detection\").project(\"package-at-front-door\").version(2).download(\"yolov8\")\n",
        "\n",
        "# Download the Bags dataset\n",
        "bags_dataset = rf.workspace(\"bagdetector\").project(\"bagdetector\").version(1).download(\"yolov8\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKL8eDtLUj0t",
        "outputId": "325bc091-46d3-409e-9edb-4b090b7457bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in bagDetection-2 to yolov8:: 100%|██████████| 27941/27941 [00:00<00:00, 39414.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to bagDetection-2 in yolov8:: 100%|██████████| 908/908 [00:00<00:00, 7948.90it/s]\n"
          ]
        }
      ],
      "source": [
        "# Download the foodbag dataset for someone like foodpenda, 2024/3/13, 11 views , 2 downloads, mAP@50=89% , Precision=83.3%, Recall=88.9%\n",
        "foodbags_dataset = rf.workspace(\"pranav-j7q56\").project(\"bagdetection-r3gze\").version(2).download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3g0VEVrSrl-",
        "outputId": "0ef3543c-76e5-4618-c4bb-82a233839ebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in delivery-man-detection--1 to yolov8:: 100%|██████████| 16422/16422 [00:00<00:00, 28870.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to delivery-man-detection--1 in yolov8:: 100%|██████████| 356/356 [00:00<00:00, 6320.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rloading Roboflow workspace...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rloading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Persons-Shopping-Bags-1 to yolov8:: 100%|██████████| 15775/15775 [00:00<00:00, 31756.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Persons-Shopping-Bags-1 in yolov8:: 100%|██████████| 715/715 [00:00<00:00, 9254.01it/s]\n"
          ]
        }
      ],
      "source": [
        "### 2. 下載人物分類資料集\n",
        "# 下載快遞員資料集（Delivery Man Detection）for temporary, because of low precision\n",
        "delivery_man_dataset = rf.workspace(\"phase-2\").project(\"delivery-man-detection\").version(1).download(\"yolov8\")\n",
        "\n",
        "# 下載人物與包裹組合資料集（Persons-Shopping Bags）\n",
        "shopping_bags_dataset = rf.workspace(\"islamia-college-peshawar\").project(\"persons-shopping-bags\").version(1).download(\"yolov8\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttR-MpAGerlq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# 創建合併資料集的目錄\n",
        "merged_dataset_dir = \"merged_dataset\"\n",
        "os.makedirs(merged_dataset_dir, exist_ok=True)\n",
        "os.makedirs(f\"{merged_dataset_dir}/train/images\", exist_ok=True)\n",
        "os.makedirs(f\"{merged_dataset_dir}/train/labels\", exist_ok=True)\n",
        "os.makedirs(f\"{merged_dataset_dir}/valid/images\", exist_ok=True)\n",
        "os.makedirs(f\"{merged_dataset_dir}/valid/labels\", exist_ok=True)\n",
        "os.makedirs(f\"{merged_dataset_dir}/test/images\", exist_ok=True)\n",
        "os.makedirs(f\"{merged_dataset_dir}/test/labels\", exist_ok=True)\n",
        "\n",
        "# 定義資料集路徑列表\n",
        "dataset_paths = [\n",
        "    package_dataset.location,\n",
        "    bags_dataset.location,\n",
        "    foodbags_dataset.location,\n",
        "    delivery_man_dataset.location,\n",
        "    shopping_bags_dataset.location\n",
        "]\n",
        "\n",
        "# 合併資料集\n",
        "for dataset_path in dataset_paths:\n",
        "    # 複製訓練集\n",
        "    for img in Path(f\"{dataset_path}/train/images\").glob(\"*.*\"):\n",
        "        shutil.copy(img, f\"{merged_dataset_dir}/train/images/\")\n",
        "    for label in Path(f\"{dataset_path}/train/labels\").glob(\"*.txt\"):\n",
        "        shutil.copy(label, f\"{merged_dataset_dir}/train/labels/\")\n",
        "\n",
        "    # 複製驗證集\n",
        "    for img in Path(f\"{dataset_path}/valid/images\").glob(\"*.*\"):\n",
        "        shutil.copy(img, f\"{merged_dataset_dir}/valid/images/\")\n",
        "    for label in Path(f\"{dataset_path}/valid/labels\").glob(\"*.txt\"):\n",
        "        shutil.copy(label, f\"{merged_dataset_dir}/valid/labels/\")\n",
        "\n",
        "    # 複製測試集\n",
        "    for img in Path(f\"{dataset_path}/test/images\").glob(\"*.*\"):\n",
        "        shutil.copy(img, f\"{merged_dataset_dir}/test/images/\")\n",
        "    for label in Path(f\"{dataset_path}/test/labels\").glob(\"*.txt\"):\n",
        "        shutil.copy(label, f\"{merged_dataset_dir}/test/labels/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juxfm5P5kXCO",
        "outputId": "0b8e93d4-98af-4ea5-d204-cc2eace2f8bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/merged_dataset\n"
          ]
        }
      ],
      "source": [
        "merged_dataset_dir='/content/merged_dataset'\n",
        "print(merged_dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_CSRztzfXE1"
      },
      "outputs": [],
      "source": [
        "# 創建標籤映射文件\n",
        "with open(f\"{merged_dataset_dir}/data.yaml\", \"w\") as f:\n",
        "    f.write(f\"train: {merged_dataset_dir}/train/images\\n\")  # Specify full path for train images\n",
        "    f.write(f\"val: {merged_dataset_dir}/valid/images\\n\")  # Specify full path for validation images\n",
        "    f.write(f\"test: {merged_dataset_dir}/test/images\\n\\n\")  # Specify full path for test images\n",
        "\n",
        "    # 定義類別映射\n",
        "    f.write(\"names:\\n\")\n",
        "    f.write(\"  0: cardboard_box\\n\")  # 紙箱\n",
        "    f.write(\"  1: bag\\n\")            # 提袋\n",
        "    f.write(\"  2: package\\n\")        # 其他包裹\n",
        "    f.write(\"  3: delivery_worker\\n\") # 郵差快遞員\n",
        "    f.write(\"  4: food_delivery\\n\")   # 送餐員\n",
        "    f.write(\"  5: other_person\\n\")    # 其他人員"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GspdTlDqfgSp"
      },
      "outputs": [],
      "source": [
        "### 5. 資料增強（針對資料量較少的類別）\n",
        "\n",
        "'''python\n",
        "from ultralytics.yolo.data.augment import Albumentations\n",
        "\n",
        "# 定義資料增強策略\n",
        "transform = Albumentations([\n",
        "    # 幾何變換\n",
        "    dict(type='ShiftScaleRotate', p=0.5),\n",
        "    dict(type='RandomRotate90', p=0.5),\n",
        "    dict(type='RandomResizedCrop', height=640, width=640, scale=(0.8, 1.0), p=0.5),\n",
        "\n",
        "    # 顏色變換\n",
        "    dict(type='RandomBrightnessContrast', p=0.5),\n",
        "    dict(type='HueSaturationValue', p=0.5),\n",
        "    dict(type='GaussianBlur', p=0.3),\n",
        "\n",
        "    # 其他變換\n",
        "    dict(type='HorizontalFlip', p=0.5),\n",
        "    dict(type='VerticalFlip', p=0.1),\n",
        "])\n",
        "\n",
        "# 資料增強可以在訓練時通過參數傳遞給 YOLOv8\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GANZNmgiC5B",
        "outputId": "d23df2a3-48a9-4ca9-c232-f540f7835271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.118-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.118-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m129.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.118 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "# 安裝 Ultralytics YOLOv8\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5wTSRfkfyYh",
        "outputId": "993362df-ea44-4a3b-b4bb-49671942446f",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.118 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/merged_dataset/data.yaml, epochs=100, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=package_person_detection, name=yolov8m_merged3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=package_person_detection/yolov8m_merged3\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 23.4MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3779170  ultralytics.nn.modules.head.Detect           [6, [192, 384, 576]]          \n",
            "Model summary: 169 layers, 25,859,794 parameters, 25,859,778 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 88.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 17.6±6.7 MB/s, size: 36.7 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/merged_dataset/train/labels... 1524 images, 3 backgrounds, 0 corrupt: 100%|██████████| 1524/1524 [00:02<00:00, 529.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/merged_dataset/train/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 85, len(boxes) = 3276. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.1±0.2 ms, read: 8.7±2.2 MB/s, size: 37.7 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/merged_dataset/valid/labels... 154 images, 0 backgrounds, 0 corrupt: 100%|██████████| 154/154 [00:00<00:00, 578.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/merged_dataset/valid/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 10, len(boxes) = 205. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to package_person_detection/yolov8m_merged3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mpackage_person_detection/yolov8m_merged3\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      1/100      6.22G      1.447      2.453       1.49          9        640: 100%|██████████| 96/96 [00:50<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:03<00:00,  1.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.236      0.466      0.245      0.141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      2/100      7.43G      1.605      1.965      1.614         17        640: 100%|██████████| 96/96 [00:50<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.364      0.337      0.132     0.0493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      3/100      6.33G      1.677      2.051      1.646         16        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.499      0.118      0.094     0.0502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      4/100      6.32G      1.713      2.114      1.704         12        640: 100%|██████████| 96/96 [00:50<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.667      0.113      0.114     0.0637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      5/100      6.32G      1.663      2.042      1.675         12        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205        0.9     0.0944      0.115     0.0681\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      6/100      6.34G      1.601       1.91      1.605         23        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.606      0.158      0.185      0.111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      7/100      6.31G      1.544      1.829       1.58         10        640: 100%|██████████| 96/96 [00:50<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.298      0.357      0.293      0.161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      8/100      6.38G      1.529      1.704      1.544         20        640: 100%|██████████| 96/96 [00:50<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:03<00:00,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205       0.25      0.625      0.342      0.201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      9/100      6.29G      1.471       1.59      1.523         34        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.224      0.549      0.366      0.216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     10/100       6.3G      1.453      1.566      1.508         25        640: 100%|██████████| 96/96 [00:49<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.293      0.418      0.343      0.193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     11/100      6.38G      1.431      1.509       1.47         23        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.704      0.374      0.451      0.277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     12/100       6.3G      1.425      1.494      1.465         26        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.558      0.493      0.479      0.278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     13/100      6.34G      1.383      1.401      1.437         23        640: 100%|██████████| 96/96 [00:49<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.298       0.44      0.402       0.23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     14/100      6.34G      1.374      1.364      1.422         17        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.523      0.583       0.49      0.313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     15/100      6.31G      1.349      1.347      1.412         17        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.456      0.531      0.409      0.275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     16/100      6.32G      1.302      1.288      1.389         24        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.618      0.512      0.551      0.338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     17/100      6.34G      1.308       1.25      1.394          9        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.392      0.517       0.44      0.293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     18/100       6.3G      1.313      1.241      1.384         21        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.471      0.603      0.489      0.325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     19/100      6.31G      1.263      1.194      1.351         20        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205       0.55      0.634      0.593      0.397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     20/100      6.34G      1.255      1.184      1.353         25        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.444      0.562      0.541      0.345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     21/100      6.33G      1.228      1.137      1.336         17        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.502      0.543      0.534       0.35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     22/100      6.31G      1.244      1.126      1.338         14        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.395      0.494      0.453      0.306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     23/100      6.33G      1.209      1.115      1.334          9        640: 100%|██████████| 96/96 [00:49<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.586      0.446      0.499       0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     24/100      6.33G      1.207      1.102      1.322          5        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.387      0.759      0.558      0.362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     25/100      6.34G      1.188      1.084      1.301         17        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.454      0.581      0.594      0.378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     26/100      6.34G      1.191       1.06      1.301          9        640: 100%|██████████| 96/96 [00:49<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.435      0.687      0.618      0.426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     27/100       6.3G      1.152      1.013      1.274         26        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.635      0.544      0.627      0.413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     28/100      6.33G      1.147       1.02      1.272         15        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.497      0.679      0.633      0.415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     29/100      6.33G       1.13     0.9701      1.257         21        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.724      0.626      0.654      0.398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     30/100      6.33G      1.114     0.9833      1.265          9        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.441      0.691      0.592      0.384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     31/100      6.33G      1.113     0.9474      1.259         19        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.676      0.523       0.65      0.455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     32/100      6.33G      1.071     0.9161      1.235         18        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.505      0.674       0.65      0.431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     33/100      6.32G      1.085     0.9034      1.235          9        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205       0.49      0.662      0.652      0.461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     34/100      6.34G      1.091     0.9208      1.234         12        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.571      0.635       0.68      0.477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     35/100      6.31G      1.072     0.9087      1.232         25        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.621      0.697      0.715       0.53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     36/100      6.31G      1.056     0.8877      1.215         19        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.734      0.529      0.646      0.454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     37/100      6.31G      1.042     0.8798      1.204         39        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.696      0.677      0.699      0.513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     38/100      6.34G      1.032     0.8524      1.208         10        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.503      0.666      0.684      0.488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     39/100      6.32G       1.02     0.8436      1.204          8        640: 100%|██████████| 96/96 [00:49<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.587      0.731      0.717       0.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     40/100      6.32G      1.021     0.8279      1.202         19        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.573      0.833      0.772      0.533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     41/100      6.31G      1.009     0.8087      1.183         17        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.723      0.621       0.74      0.503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     42/100      6.32G      1.004     0.7977      1.182         13        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.813      0.634      0.761       0.55\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     43/100      6.31G     0.9955     0.8025       1.19         19        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.532      0.817      0.736      0.521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     44/100      6.31G      0.984     0.7695      1.167         23        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.707      0.711       0.75      0.537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     45/100      6.38G     0.9702     0.7627      1.159         15        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.762      0.609      0.712       0.47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     46/100      6.34G     0.9451     0.7487       1.15         26        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.745        0.7      0.782      0.582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     47/100      6.34G     0.9258     0.7442      1.137         16        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.692      0.684      0.754      0.534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     48/100      6.33G     0.9442     0.7458      1.159         16        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.808       0.66      0.715      0.482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     49/100      6.33G     0.9151       0.71      1.121         29        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.637      0.773      0.757      0.524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     50/100      6.31G     0.9115     0.6984      1.137         31        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.667      0.637      0.708      0.492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     51/100      6.38G     0.9191     0.7135      1.132         31        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.647      0.712      0.749      0.537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     52/100      6.32G     0.9103     0.7126      1.128         15        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.564       0.74      0.732      0.543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     53/100      6.34G     0.8804      0.678      1.121         17        640: 100%|██████████| 96/96 [00:49<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.716      0.718      0.736      0.547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     54/100      6.32G     0.8924     0.6944      1.119         11        640: 100%|██████████| 96/96 [00:50<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.632      0.765      0.742      0.514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     55/100      6.31G     0.8868     0.6935      1.121         10        640: 100%|██████████| 96/96 [00:50<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.691      0.728      0.802      0.585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     56/100      6.34G     0.8548     0.6486      1.101          7        640: 100%|██████████| 96/96 [00:50<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205       0.72      0.781      0.805      0.578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     57/100      6.34G      0.866     0.6627      1.101         22        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.654      0.705      0.733      0.527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     58/100      6.33G     0.8528     0.6365      1.099         28        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.754       0.69      0.778      0.558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     59/100      6.33G      0.836     0.6309      1.098         14        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.775      0.673      0.767      0.548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     60/100      6.31G     0.8262     0.6166      1.082          9        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.789      0.656      0.765      0.562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     61/100      6.32G     0.8242     0.6127      1.081         12        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.635      0.735      0.763      0.546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     62/100      6.31G     0.8276     0.6204       1.08         10        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205       0.75      0.716       0.79      0.587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     63/100      6.33G     0.8017     0.6006      1.079         10        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.749       0.63      0.734      0.513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     64/100       6.3G     0.7935     0.5888       1.06         16        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.805       0.74      0.793      0.581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     65/100      6.34G     0.7838     0.5862      1.074         22        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.748      0.623      0.732      0.536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     66/100      6.32G     0.8027     0.5753      1.068          7        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205        0.8      0.628      0.753      0.538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     67/100      6.34G      0.767      0.565      1.053         13        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.641      0.709      0.698      0.494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     68/100      6.31G      0.786     0.5676      1.059         12        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.684      0.657      0.715      0.518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     69/100      6.33G     0.7653     0.5608      1.052         32        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.697      0.798      0.777      0.554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     70/100      6.29G     0.7706     0.5735      1.058         32        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.775      0.766      0.793      0.575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     71/100      6.34G     0.7671      0.558      1.065         11        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.697      0.756      0.748      0.542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     72/100      6.34G     0.7635     0.5623       1.07          6        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.739       0.71      0.759       0.56\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     73/100      6.39G     0.7365     0.5283      1.039         14        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.649      0.735      0.736      0.541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     74/100      6.31G     0.7341     0.5236      1.036         18        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.778      0.705       0.77      0.558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     75/100      6.33G     0.7413     0.5419      1.045          9        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.732      0.732       0.78      0.576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     76/100      6.34G     0.7138     0.5166      1.026          9        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.738      0.772      0.791      0.544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     77/100      6.39G     0.7193      0.503      1.033         14        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.703      0.795      0.784      0.544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     78/100      6.31G     0.6982     0.5052      1.027         18        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.804       0.71      0.772      0.533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     79/100      6.31G     0.7033     0.5024      1.024         21        640: 100%|██████████| 96/96 [00:49<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.708      0.738      0.783      0.546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     80/100      6.31G     0.7003     0.4922      1.025          8        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205       0.75      0.736       0.76      0.554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     81/100      6.37G     0.6865     0.4872      1.015         23        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.708      0.784       0.75      0.551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     82/100      6.32G     0.6849     0.4835      1.009         18        640: 100%|██████████| 96/96 [00:49<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.665      0.765      0.732      0.527\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 62, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "82 epochs completed in 1.322 hours.\n",
            "Optimizer stripped from package_person_detection/yolov8m_merged3/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from package_person_detection/yolov8m_merged3/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating package_person_detection/yolov8m_merged3/weights/best.pt...\n",
            "Ultralytics 8.3.118 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 92 layers, 25,843,234 parameters, 0 gradients, 78.7 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:04<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205      0.749      0.716       0.79      0.587\n",
            "         cardboard_box        109        125      0.903      0.819      0.917      0.741\n",
            "                   bag          8          8      0.803          1      0.995      0.802\n",
            "               package          7         14       0.64      0.429      0.552      0.363\n",
            "       delivery_worker          8          8      0.551       0.75      0.781      0.569\n",
            "          other_person         22         50      0.849       0.58      0.704      0.461\n",
            "Speed: 0.3ms preprocess, 9.9ms inference, 0.0ms loss, 7.2ms postprocess per image\n",
            "Results saved to \u001b[1mpackage_person_detection/yolov8m_merged3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "## 三、模型訓練\n",
        "\n",
        "### 1. 基本訓練\n",
        "\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# 載入預訓練模型\n",
        "model = YOLO('yolov8m.pt')  # 使用中型 YOLOv8 模型\n",
        "\n",
        "# 開始訓練\n",
        "results = model.train(\n",
        "    data=f\"{merged_dataset_dir}/data.yaml\",\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    patience=20,\n",
        "    save=True,\n",
        "    device=0,  # 使用 GPU 0\n",
        "    project=\"package_person_detection\",\n",
        "    name=\"yolov8m_merged\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofXdDm7CgHt2"
      },
      "outputs": [],
      "source": [
        "### 2. 進階訓練設置\n",
        "\n",
        "'''\n",
        "# 使用更多進階參數的訓練\n",
        "results = model.train(\n",
        "    data=f\"{merged_dataset_dir}/data.yaml\",\n",
        "    epochs=200,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    patience=30,\n",
        "    save=True,\n",
        "    device=0,\n",
        "    project=\"package_person_detection\",\n",
        "    name=\"yolov8m_advanced\",\n",
        "    lr0=0.01,\n",
        "    lrf=0.001,\n",
        "    momentum=0.937,\n",
        "    weight_decay=0.0005,\n",
        "    warmup_epochs=3,\n",
        "    warmup_momentum=0.8,\n",
        "    warmup_bias_lr=0.1,\n",
        "    box=7.5,\n",
        "    cls=0.5,\n",
        "    dfl=1.5,\n",
        "    fl_gamma=0.0,\n",
        "    label_smoothing=0.0,\n",
        "    nbs=64,\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    degrees=0.0,\n",
        "    translate=0.1,\n",
        "    scale=0.5,\n",
        "    shear=0.0,\n",
        "    perspective=0.0,\n",
        "    flipud=0.0,\n",
        "    fliplr=0.5,\n",
        "    mosaic=1.0,\n",
        "    mixup=0.0,\n",
        "    copy_paste=0.0\n",
        ")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiKMgB3lgQB_"
      },
      "source": [
        "### 3. 使用 Ultralytics 進行人工標註（針對缺乏資料的類別）\n",
        "\n",
        "```python\n",
        "# 使用 Ultralytics 標註工具\n",
        "# 1. 安裝 labelImg 工具\n",
        "# pip install labelImg\n",
        "\n",
        "# 2. 啟動標註工具\n",
        "# labelImg path/to/images path/to/labels/output yolo\n",
        "\n",
        "# 3. 標註完成後，將新標註的資料加入訓練集\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHoACAsUgaPV"
      },
      "source": [
        "## 四、模型評估與優化\n",
        "\n",
        "### 1. 模型評估"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGBlafyp5Hif",
        "outputId": "757f73b7-5b1e-4d1c-be4e-8cb212bec539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.118 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1477.0±568.5 MB/s, size: 35.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/merged_dataset/valid/labels.cache... 154 images, 0 backgrounds, 0 corrupt: 100%|██████████| 154/154 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 10, len(boxes) = 205. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        154        205       0.75      0.716       0.79      0.586\n",
            "         cardboard_box        109        125      0.903       0.82      0.917      0.734\n",
            "                   bag          8          8       0.81          1      0.995      0.802\n",
            "               package          7         14      0.639      0.429      0.552      0.364\n",
            "       delivery_worker          8          8      0.552       0.75      0.781      0.569\n",
            "          other_person         22         50      0.844       0.58      0.704      0.461\n",
            "Speed: 4.2ms preprocess, 22.1ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1mpackage_person_detection/yolov8m_merged36\u001b[0m\n",
            "mAP50: 0.7898936494774601\n",
            "mAP50-95: 0.5859956690298884\n"
          ]
        }
      ],
      "source": [
        "# 在測試集上評估模型\n",
        "results = model.val(data=f\"{merged_dataset_dir}/data.yaml\")\n",
        "\n",
        "# 查看評估指標\n",
        "# metrics = results.box.metrics.dict  # This line is causing the error\n",
        "# metrics = results.box.metrics  # Access the DetMetrics object # This line is redundant.\n",
        "# Access metrics directly from results.box\n",
        "print(f\"mAP50: {results.box.map50}\")\n",
        "print(f\"mAP50-95: {results.box.map}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrwM9HyvHVrU",
        "outputId": "1ede5bbe-891a-4c30-ce4a-fb3fdecf5b85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0: Precision = 0.9031, Recall = 0.8198\n",
            "Class 1: Precision = 0.8104, Recall = 1.0000\n",
            "Class 2: Precision = 0.6389, Recall = 0.4286\n",
            "Class 3: Precision = 0.5525, Recall = 0.7500\n",
            "Class 4: Precision = 0.8441, Recall = 0.5800\n"
          ]
        }
      ],
      "source": [
        "# Get precision and recall for each class\n",
        "precision = results.box.p\n",
        "recall = results.box.r\n",
        "\n",
        "# Print precision and recall for each class\n",
        "for i, (p, r) in enumerate(zip(precision, recall)):\n",
        "    print(f\"Class {i}: Precision = {p:.4f}, Recall = {r:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVXeL9cJJ-8R",
        "outputId": "73092630-a526-47d8-fd74-b32519b44437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class cardboard_box       : \tPrecision = 0.9031, \tRecall = 0.8198\n",
            "Class bag                 : \tPrecision = 0.8104, \tRecall = 1.0000\n",
            "Class package             : \tPrecision = 0.6389, \tRecall = 0.4286\n",
            "Class delivery_worker     : \tPrecision = 0.5525, \tRecall = 0.7500\n",
            "Class food_delivery       : \tPrecision = 0.8441, \tRecall = 0.5800\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "# 讀取 data.yaml 檔案以獲取類別名稱\n",
        "with open(f\"{merged_dataset_dir}/data.yaml\", 'r') as f:\n",
        "    data = yaml.safe_load(f)\n",
        "class_names = data['names']  # 獲取類別名稱字典\n",
        "\n",
        "# Get precision and recall for each class\n",
        "precision = results.box.p\n",
        "recall = results.box.r\n",
        "\n",
        "# Print precision and recall for each class with names\n",
        "for i, (p, r) in enumerate(zip(precision, recall)):\n",
        "    class_name = class_names[i]  # 獲取類別名稱\n",
        "    print(f\"Class {class_name:<20}: \\tPrecision = {p:.4f}, \\tRecall = {r:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4TEaw1Qglq0"
      },
      "source": [
        "### 2. 模型優化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9I3uNcEgj36"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# 模型剪枝（減少模型大小）\n",
        "pruned_model = model.prune(0.3)  # 剪枝 30% 的權重\n",
        "\n",
        "# 模型量化（減少模型大小和推理時間）\n",
        "quantized_model = model.export(format='onnx', dynamic=True, simplify=True)\n",
        "\n",
        "# 模型蒸餾（從大模型學習到小模型）\n",
        "teacher = YOLO('yolov8l.pt')  # 大模型作為教師\n",
        "student = YOLO('yolov8s.pt')  # 小模型作為學生\n",
        "\n",
        "# 使用教師模型的知識蒸餾到學生模型\n",
        "student.train(\n",
        "    data=f\"{merged_dataset_dir}/data.yaml\",\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    project=\"package_person_detection\",\n",
        "    name=\"distilled_model\",\n",
        "    teacher=teacher\n",
        ")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovKdyEe-g5mJ"
      },
      "source": [
        "## 五、模型部署\n",
        "\n",
        "### 1. 模型導出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dThIYydAg8Bv",
        "outputId": "e0197c65-c33c-48d1-f7e5-bc633552bba0",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.118 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'package_person_detection/yolov8m_merged3/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 10, 8400) (49.6 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxslim\n",
            "  Downloading onnxslim-0.1.50-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxslim) (1.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxslim) (24.2)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (25.2.10)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxslim) (1.3.0)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 303.7 MB/s eta 0:00:00\n",
            "Downloading onnxslim-0.1.50-py3-none-any.whl (144 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 144.5/144.5 kB 225.8 MB/s eta 0:00:00\n",
            "Downloading onnxruntime_gpu-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.8/280.8 MB 168.9 MB/s eta 0:00:00\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 189.8 MB/s eta 0:00:00\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 228.3 MB/s eta 0:00:00\n",
            "Installing collected packages: onnx, humanfriendly, onnxslim, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-gpu-1.21.1 onnxslim-0.1.50\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 18.2s, installed 3 packages: ['onnx>=1.12.0', 'onnxslim', 'onnxruntime-gpu']\n",
            "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.50...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 40.6s, saved as 'package_person_detection/yolov8m_merged3/weights/best.onnx' (98.7 MB)\n",
            "\n",
            "Export complete (43.8s)\n",
            "Results saved to \u001b[1m/content/package_person_detection/yolov8m_merged3/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=package_person_detection/yolov8m_merged3/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=package_person_detection/yolov8m_merged3/weights/best.onnx imgsz=640 data=/content/merged_dataset/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Ultralytics 8.3.118 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'package_person_detection/yolov8m_merged3/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 10, 8400) (49.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.50...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 26.6s, saved as 'package_person_detection/yolov8m_merged3/weights/best.onnx' (98.7 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['tensorrt>7.0.0,!=10.1.0'] not found, attempting AutoUpdate...\n",
            "Collecting tensorrt!=10.1.0,>7.0.0\n",
            "  Downloading tensorrt-10.9.0.34.tar.gz (40 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.7/40.7 kB 5.3 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting tensorrt_cu12==10.9.0.34 (from tensorrt!=10.1.0,>7.0.0)\n",
            "  Downloading tensorrt_cu12-10.9.0.34.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting tensorrt_cu12_libs==10.9.0.34 (from tensorrt_cu12==10.9.0.34->tensorrt!=10.1.0,>7.0.0)\n",
            "  Downloading tensorrt_cu12_libs-10.9.0.34.tar.gz (704 bytes)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting tensorrt_cu12_bindings==10.9.0.34 (from tensorrt_cu12==10.9.0.34->tensorrt!=10.1.0,>7.0.0)\n",
            "  Downloading tensorrt_cu12_bindings-10.9.0.34-cp311-none-manylinux_2_28_x86_64.whl.metadata (606 bytes)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.11/dist-packages (from tensorrt_cu12_libs==10.9.0.34->tensorrt_cu12==10.9.0.34->tensorrt!=10.1.0,>7.0.0) (12.4.127)\n",
            "Downloading tensorrt_cu12_bindings-10.9.0.34-cp311-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 38.3 MB/s eta 0:00:00\n",
            "Building wheels for collected packages: tensorrt, tensorrt_cu12, tensorrt_cu12_libs\n",
            "  Building wheel for tensorrt (setup.py): started\n",
            "  Building wheel for tensorrt (setup.py): finished with status 'done'\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.9.0.34-py2.py3-none-any.whl size=46629 sha256=20bf8616a435f80f04891804ea1db18a5331d68eb0123db50c640beaca1bba95\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ojwer6s1/wheels/3a/4d/72/f28cb367f1435d026243047d4f60fde8f1c9cbb06a204f842f\n",
            "  Building wheel for tensorrt_cu12 (setup.py): started\n",
            "  Building wheel for tensorrt_cu12 (setup.py): finished with status 'done'\n",
            "  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.9.0.34-py2.py3-none-any.whl size=17466 sha256=f135f7832670cc4ba4e5e0a0b384b942f207c8716e01276c688bc559b8287b87\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ojwer6s1/wheels/75/09/76/6b405075fe4c04097f5713ec0a688df7892aaee823bc141952\n",
            "  Building wheel for tensorrt_cu12_libs (pyproject.toml): started\n",
            "  Building wheel for tensorrt_cu12_libs (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for tensorrt_cu12_libs: filename=tensorrt_cu12_libs-10.9.0.34-py2.py3-none-manylinux_2_28_x86_64.whl size=3103291777 sha256=4a82f0bda2874596f202f6edc8dae99b86a3c4ec2fa142a9c847c4d3a57864a0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ojwer6s1/wheels/33/d0/06/35d7b3006eead25828debb658da848328ebfd38962a2bcd096\n",
            "Successfully built tensorrt tensorrt_cu12 tensorrt_cu12_libs\n",
            "Installing collected packages: tensorrt_cu12_bindings, tensorrt_cu12_libs, tensorrt_cu12, tensorrt\n",
            "Successfully installed tensorrt-10.9.0.34 tensorrt_cu12-10.9.0.34 tensorrt_cu12_bindings-10.9.0.34 tensorrt_cu12_libs-10.9.0.34\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 208.1s, installed 1 package: ['tensorrt>7.0.0,!=10.1.0']\n",
            "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.9.0.34...\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(-1, 3, -1, -1) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(-1, 10, -1) DataType.FLOAT\n",
            "WARNING ⚠️ \u001b[34m\u001b[1mTensorRT:\u001b[0m 'dynamic=True' model requires max batch size, i.e. 'batch=16'\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as package_person_detection/yolov8m_merged3/weights/best.engine\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 356.0s, saved as 'package_person_detection/yolov8m_merged3/weights/best.engine' (124.7 MB)\n",
            "\n",
            "Export complete (356.5s)\n",
            "Results saved to \u001b[1m/content/package_person_detection/yolov8m_merged3/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=package_person_detection/yolov8m_merged3/weights/best.engine imgsz=640  \n",
            "Validate:        yolo val task=detect model=package_person_detection/yolov8m_merged3/weights/best.engine imgsz=640 data=/content/merged_dataset/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Ultralytics 8.3.118 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.00GHz)\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "ERROR ❌️ argument 'dynamic' is not supported for format='coreml'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-f3dc53ad4dc2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 導出為 CoreML 格式（適用於 iOS 設備）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coreml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 導出為 TensorFlow SavedModel 格式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         }  # method defaults\n\u001b[1;32m    726\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcustom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"export\"\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# highest priority args on the right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mExporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     def train(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;31m# Argument compatibility checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mfmt_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmts_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Arguments\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mvalidate_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36mvalidate_args\u001b[0;34m(format, passed_args, valid_args)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mnot_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnot_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"ERROR ❌️ argument '{arg}' is not supported for format='{format}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: ERROR ❌️ argument 'dynamic' is not supported for format='coreml'"
          ]
        }
      ],
      "source": [
        "# 導出為 ONNX 格式（適用於多種推理框架）\n",
        "model.export(format='onnx', dynamic=True, simplify=True)\n",
        "\n",
        "# 導出為 TensorRT 格式（NVIDIA GPU 上的高性能推理）\n",
        "model.export(format='engine', dynamic=True, simplify=True, device=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q_EfxZe9OICC",
        "outputId": "d389a4cd-36ef-4a87-cb02-4a85d57b9e4e",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.118 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'package_person_detection/yolov8m_merged3/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 10, 8400) (49.6 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['coremltools>=8.0'] not found, attempting AutoUpdate...\n",
            "Collecting coremltools>=8.0\n",
            "  Downloading coremltools-8.2-cp311-none-manylinux1_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.11/dist-packages (from coremltools>=8.0) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from coremltools>=8.0) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from coremltools>=8.0) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from coremltools>=8.0) (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from coremltools>=8.0) (24.2)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.11/dist-packages (from coremltools>=8.0) (25.3.0)\n",
            "Collecting cattrs (from coremltools>=8.0)\n",
            "  Downloading cattrs-24.1.3-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pyaml (from coremltools>=8.0)\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml->coremltools>=8.0) (6.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->coremltools>=8.0) (1.3.0)\n",
            "Downloading coremltools-8.2-cp311-none-manylinux1_x86_64.whl (2.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 49.4 MB/s eta 0:00:00\n",
            "Downloading cattrs-24.1.3-py3-none-any.whl (66 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.5/66.5 kB 299.0 MB/s eta 0:00:00\n",
            "Downloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, cattrs, coremltools\n",
            "Successfully installed cattrs-24.1.3 coremltools-8.2 pyaml-25.1.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 5.5s, installed 1 package: ['coremltools>=8.0']\n",
            "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:coremltools:scikit-learn version 1.6.1 is not supported. Minimum required version: 0.17. Maximum required version: 1.5.1. Disabling scikit-learn conversion API.\n",
            "WARNING:coremltools:XGBoost version 2.1.4 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n",
            "WARNING:coremltools:TensorFlow version 2.18.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n",
            "WARNING:coremltools:Torch version 2.6.0+cu124 has not been tested with coremltools. You may run into unexpected errors. Torch 2.5.0 is the most recent version that has been tested.\n",
            "WARNING:coremltools:Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n",
            "WARNING:coremltools:Failed to load _MLCPUComputeDeviceProxy: No module named 'coremltools.libcoremlpython'\n",
            "WARNING:coremltools:Failed to load _MLGPUComputeDeviceProxy: No module named 'coremltools.libcoremlpython'\n",
            "WARNING:coremltools:Failed to load _MLNeuralEngineComputeDeviceProxy: No module named 'coremltools.libcoremlpython'\n",
            "WARNING:coremltools:Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n",
            "WARNING:coremltools:Failed to load _MLComputePlanProxy: No module named 'coremltools.libcoremlpython'\n",
            "WARNING:coremltools:Failed to load _MLModelProxy: No module named 'coremltools.libcoremlpython'\n",
            "WARNING:coremltools:Failed to load _MLModelAssetProxy: No module named 'coremltools.libcoremlpython'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mCoreML:\u001b[0m starting export with coremltools 8.2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 720/721 [00:00<00:00, 3343.52 ops/s]\n",
            "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 93.39 passes/s]\n",
            "Running MIL default pipeline: 100%|██████████| 89/89 [00:02<00:00, 33.41 passes/s]\n",
            "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 89.17 passes/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mCoreML:\u001b[0m export success ✅ 27.1s, saved as 'package_person_detection/yolov8m_merged3/weights/best.mlpackage' (49.5 MB)\n",
            "\n",
            "Export complete (28.9s)\n",
            "Results saved to \u001b[1m/content/package_person_detection/yolov8m_merged3/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=package_person_detection/yolov8m_merged3/weights/best.mlpackage imgsz=640  \n",
            "Validate:        yolo val task=detect model=package_person_detection/yolov8m_merged3/weights/best.mlpackage imgsz=640 data=/content/merged_dataset/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Ultralytics 8.3.118 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.00GHz)\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "ERROR ❌️ argument 'dynamic' is not supported for format='saved_model'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-8d42c6bea6a2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 導出為 TensorFlow SavedModel 格式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saved_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         }  # method defaults\n\u001b[1;32m    726\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcustom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"export\"\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# highest priority args on the right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mExporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     def train(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;31m# Argument compatibility checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mfmt_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmts_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Arguments\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mvalidate_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/exporter.py\u001b[0m in \u001b[0;36mvalidate_args\u001b[0;34m(format, passed_args, valid_args)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mnot_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnot_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"ERROR ❌️ argument '{arg}' is not supported for format='{format}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: ERROR ❌️ argument 'dynamic' is not supported for format='saved_model'"
          ]
        }
      ],
      "source": [
        "# 導出為 CoreML 格式（適用於 iOS 設備）\n",
        "model.export(format='coreml', simplify=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "-IZxatrTOXWc",
        "outputId": "3c031f97-8da0-4a4c-fb06-6a40749bb456",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.118 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'package_person_detection/yolov8m_merged3/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 10, 8400) (49.6 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0', 'onnx2tf>=1.26.3'] not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting sng4onnx>=1.0.1\n",
            "  Downloading sng4onnx-1.0.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting onnx_graphsurgeon>=0.3.26\n",
            "  Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting ai-edge-litert>=1.2.0\n",
            "  Downloading ai_edge_litert-1.2.0-cp311-cp311-manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting onnx2tf>=1.26.3\n",
            "  Downloading onnx2tf-1.27.2-py3-none-any.whl.metadata (147 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.7/147.7 kB 8.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnx_graphsurgeon>=0.3.26) (2.0.2)\n",
            "Requirement already satisfied: onnx>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from onnx_graphsurgeon>=0.3.26) (1.17.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert>=1.2.0) (25.2.10)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.14.0->onnx_graphsurgeon>=0.3.26) (5.29.4)\n",
            "Downloading sng4onnx-1.0.4-py3-none-any.whl (5.9 kB)\n",
            "Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl (57 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.9/57.9 kB 249.0 MB/s eta 0:00:00\n",
            "Downloading ai_edge_litert-1.2.0-cp311-cp311-manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 102.7 MB/s eta 0:00:00\n",
            "Downloading onnx2tf-1.27.2-py3-none-any.whl (446 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 446.6/446.6 kB 289.3 MB/s eta 0:00:00\n",
            "Installing collected packages: sng4onnx, onnx2tf, ai-edge-litert, onnx_graphsurgeon\n",
            "Successfully installed ai-edge-litert-1.2.0 onnx2tf-1.27.2 onnx_graphsurgeon-0.5.8 sng4onnx-1.0.4\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 6.4s, installed 4 packages: ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0', 'onnx2tf>=1.26.3']\n",
            "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.11M/1.11M [00:00<00:00, 30.7MB/s]\n",
            "Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100%|██████████| 1/1 [00:00<00:00, 50.74file/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.50...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 3.5s, saved as 'package_person_detection/yolov8m_merged3/weights/best.onnx' (98.8 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.27.2...\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 190.1s, saved as 'package_person_detection/yolov8m_merged3/weights/best_saved_model' (247.6 MB)\n",
            "\n",
            "Export complete (192.0s)\n",
            "Results saved to \u001b[1m/content/package_person_detection/yolov8m_merged3/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=package_person_detection/yolov8m_merged3/weights/best_saved_model imgsz=640  \n",
            "Validate:        yolo val task=detect model=package_person_detection/yolov8m_merged3/weights/best_saved_model imgsz=640 data=/content/merged_dataset/data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'package_person_detection/yolov8m_merged3/weights/best_saved_model'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 導出為 TensorFlow SavedModel 格式\n",
        "model.export(format='saved_model', simplify=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmSxAhPnhBhU"
      },
      "source": [
        "### 2. 部署到出入口即時包裹與人物意圖偵測系統"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qdiAxzcUOQN"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output  # << 重要：清除上個frame的顯示"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 載入模型\n",
        "model = YOLO('/content/package_person_detection/yolov8m_merged3/weights/best.pt')\n",
        "\n",
        "# 設定參數\n",
        "conf_threshold = 0.5\n",
        "video_source = 1\n",
        "detect_interval = 15  # 每15張推論一次\n",
        "snapshot_interval_sec = 5  # 每5秒存一張快照\n",
        "snapshot_dir = \"/content/snapshots\"\n",
        "os.makedirs(snapshot_dir, exist_ok=True)\n",
        "\n",
        "if video_source == 0:\n",
        "    def get_camera_stream(ip, username, password, channel=1):\n",
        "        rtsp_url = f\"rtsp://{username}:{password}@{ip}/Streaming/Channels/{channel}01\"\n",
        "        cap = cv2.VideoCapture(rtsp_url)\n",
        "        return cap\n",
        "    camera = get_camera_stream(\"106.107.183.134\", \"admin\", \"Qazwsx1122\")\n",
        "elif video_source == 1:\n",
        "    video_path = \"videoplayback.mp4\"  # 替換成你的影片路徑\n",
        "    camera = cv2.VideoCapture(video_path)\n",
        "else:\n",
        "    print(\"Invalid video source selected.\")\n",
        "    exit()\n",
        "\n",
        "# 取得影片資訊\n",
        "fps = camera.get(cv2.CAP_PROP_FPS) or 30  # 預設30fps\n",
        "frame_width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "snapshot_interval_frames = int(fps * snapshot_interval_sec)\n",
        "\n",
        "# 設定執行時間\n",
        "end_time = time.time() + 300  # 最長5分鐘\n",
        "\n",
        "frame_count = 0\n",
        "inference_count = 0\n",
        "latest_detected_classes = defaultdict(int)   # 最新一輪推論結果\n",
        "cumulative_detected_classes = defaultdict(int)  # 累積所有推論結果\n",
        "latest_names = []\n",
        "frames = []  # 保存所有處理後的frame\n",
        "\n",
        "# 主循環\n",
        "while time.time() < end_time:\n",
        "    ret, frame = camera.read()\n",
        "    if not ret:\n",
        "        print(\"無法讀取影像，可能是影片結束了。\")\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 每detect_interval張推論一次\n",
        "    if frame_count % detect_interval == 0:\n",
        "        results = model(frame, conf=conf_threshold)\n",
        "        boxes = results[0].boxes.data.cpu().numpy() if results[0].boxes.data is not None else []\n",
        "        latest_names = results[0].names\n",
        "        inference_count += 1\n",
        "\n",
        "        # 更新最新推論結果 + 累積推論統計\n",
        "        latest_detected_classes = defaultdict(int)\n",
        "        for det in boxes:\n",
        "            _, _, _, _, score, class_id = det\n",
        "            if score >= conf_threshold:\n",
        "                class_name = latest_names[int(class_id)]\n",
        "                latest_detected_classes[class_name] += 1\n",
        "                cumulative_detected_classes[class_name] += 1\n",
        "\n",
        "    # 畫推論資訊文字在frame上\n",
        "    annotated_frame = frame.copy()\n",
        "\n",
        "    # 左上角推論次數\n",
        "    cv2.putText(annotated_frame, f\"Inference Count: {inference_count}\", (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "    # 右上角目前frame編號\n",
        "    cv2.putText(annotated_frame, f\"Frame: {frame_count}\", (frame_width - 250, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)\n",
        "\n",
        "    # 左下角顯示累積偵測統計\n",
        "    y_offset = 70\n",
        "    for cls_name, count in cumulative_detected_classes.items():\n",
        "        text = f\"{cls_name}: {count}\"\n",
        "        cv2.putText(annotated_frame, text, (10, y_offset),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "        y_offset += 40\n",
        "\n",
        "    # 存進frames清單\n",
        "    frames.append(annotated_frame)\n",
        "\n",
        "    # 每隔snapshot_interval_frames儲存一張快照\n",
        "    if frame_count % snapshot_interval_frames == 0:\n",
        "        snapshot_path = os.path.join(snapshot_dir, f\"snapshot_frame_{frame_count}.jpg\")\n",
        "        cv2.imwrite(snapshot_path, annotated_frame)\n",
        "        print(f\"儲存快照: {snapshot_path}\")\n",
        "\n",
        "camera.release()\n",
        "print(f\"總共處理了 {len(frames)} 張frame。\")\n",
        "\n",
        "# --- 合成影片 ---\n",
        "output_video_path = '/content/inference_output.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "for frame in frames:\n",
        "    out.write(frame)\n",
        "out.release()\n",
        "\n",
        "print(f\"影片已儲存到 {output_video_path}\")\n",
        "\n",
        "# 🔥 🔥 🔥 在最後列印累積推論結果 🔥 🔥 🔥\n",
        "print(\"\\n===== 最後累積推論結果 =====\")\n",
        "for cls_name, count in cumulative_detected_classes.items():\n",
        "    print(f\"{cls_name}: {count} 次\")\n",
        "print(\"==============================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FBdG0vk7ip3C",
        "outputId": "6e24edeb-e3dd-44eb-a461-23bec5724ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 26.3ms\n",
            "Speed: 3.4ms preprocess, 26.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.7ms\n",
            "Speed: 2.8ms preprocess, 22.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.7ms\n",
            "Speed: 2.8ms preprocess, 22.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.7ms\n",
            "Speed: 3.0ms preprocess, 22.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.7ms\n",
            "Speed: 2.6ms preprocess, 22.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.7ms\n",
            "Speed: 2.5ms preprocess, 22.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 2.5ms preprocess, 22.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.7ms\n",
            "Speed: 2.7ms preprocess, 22.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "儲存快照: /content/snapshots/snapshot_frame_149.jpg\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.7ms\n",
            "Speed: 2.6ms preprocess, 22.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.7ms\n",
            "Speed: 2.7ms preprocess, 22.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 2.2ms preprocess, 22.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 5.2ms preprocess, 22.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 3.5ms preprocess, 22.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bag, 25.5ms\n",
            "Speed: 6.1ms preprocess, 25.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "儲存快照: /content/snapshots/snapshot_frame_298.jpg\n",
            "\n",
            "0: 384x640 (no detections), 23.6ms\n",
            "Speed: 2.5ms preprocess, 23.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.7ms preprocess, 25.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 26.1ms\n",
            "Speed: 2.6ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 3.0ms preprocess, 25.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.8ms preprocess, 25.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.7ms preprocess, 25.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.7ms preprocess, 25.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "儲存快照: /content/snapshots/snapshot_frame_447.jpg\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 27.7ms\n",
            "Speed: 2.7ms preprocess, 27.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 26.0ms\n",
            "Speed: 2.5ms preprocess, 26.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 4.8ms preprocess, 25.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.7ms preprocess, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.4ms\n",
            "Speed: 2.7ms preprocess, 25.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 3.3ms preprocess, 25.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 package, 25.3ms\n",
            "Speed: 2.7ms preprocess, 25.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "儲存快照: /content/snapshots/snapshot_frame_596.jpg\n",
            "\n",
            "0: 384x640 1 package, 25.2ms\n",
            "Speed: 3.5ms preprocess, 25.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 package, 25.3ms\n",
            "Speed: 2.9ms preprocess, 25.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 package, 25.2ms\n",
            "Speed: 2.3ms preprocess, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.0ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 3.7ms preprocess, 25.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.3ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.2ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.4ms\n",
            "Speed: 2.7ms preprocess, 25.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 3.4ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "儲存快照: /content/snapshots/snapshot_frame_745.jpg\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.1ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.6ms\n",
            "Speed: 2.5ms preprocess, 25.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 3.0ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 3.3ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 3.2ms preprocess, 25.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.7ms preprocess, 25.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 3.2ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.8ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "儲存快照: /content/snapshots/snapshot_frame_894.jpg\n",
            "\n",
            "0: 384x640 (no detections), 25.5ms\n",
            "Speed: 2.5ms preprocess, 25.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.5ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 3.0ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 4.2ms preprocess, 25.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.9ms preprocess, 25.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.5ms\n",
            "Speed: 2.4ms preprocess, 25.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 3.7ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 3.1ms preprocess, 25.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.6ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.1ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "儲存快照: /content/snapshots/snapshot_frame_1043.jpg\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.7ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.7ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.5ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.5ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.5ms preprocess, 25.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.5ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.8ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 3.6ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.9ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "儲存快照: /content/snapshots/snapshot_frame_1192.jpg\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.4ms preprocess, 25.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.5ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.5ms preprocess, 25.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.5ms\n",
            "Speed: 2.6ms preprocess, 25.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.3ms preprocess, 25.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.8ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.8ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 3.2ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "儲存快照: /content/snapshots/snapshot_frame_1341.jpg\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 3.3ms preprocess, 25.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 3.1ms preprocess, 25.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 3.1ms preprocess, 25.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.8ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 3.5ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.7ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 2.5ms preprocess, 25.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "無法讀取影像，可能是影片結束了。\n",
            "總共處理了 1469 張frame。\n",
            "影片已儲存到 /content/inference_output.mp4\n",
            "\n",
            "===== 最後累積推論結果 =====\n",
            "bag: 1 次\n",
            "package: 4 次\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/package_person_detection.zip /content/package_person_detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SJDJBOqVkTDh",
        "outputId": "1d0580ae-a30c-492d-9960-20084a167116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/package_person_detection/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/confusion_matrix_normalized.png (deflated 22%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/F1_curve.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/val_batch1_labels.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/val_batch2_pred.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/val_batch1_pred.jpg (deflated 6%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/PR_curve.png (deflated 13%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/R_curve.png (deflated 9%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/confusion_matrix.png (deflated 26%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/val_batch2_labels.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/P_curve.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/val_batch0_labels.jpg (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged32/val_batch0_pred.jpg (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/confusion_matrix_normalized.png (deflated 22%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/F1_curve.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/val_batch1_labels.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/val_batch2_pred.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/val_batch1_pred.jpg (deflated 6%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/PR_curve.png (deflated 13%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/R_curve.png (deflated 9%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/confusion_matrix.png (deflated 26%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/val_batch2_labels.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/P_curve.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/val_batch0_labels.jpg (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged35/val_batch0_pred.jpg (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/confusion_matrix_normalized.png (deflated 22%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/F1_curve.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/val_batch1_labels.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/val_batch2_pred.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/val_batch1_pred.jpg (deflated 6%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/PR_curve.png (deflated 13%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/R_curve.png (deflated 9%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/confusion_matrix.png (deflated 26%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/val_batch2_labels.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/P_curve.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/val_batch0_labels.jpg (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged34/val_batch0_pred.jpg (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/confusion_matrix_normalized.png (deflated 22%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/F1_curve.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/val_batch1_labels.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/val_batch2_pred.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/val_batch1_pred.jpg (deflated 6%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/PR_curve.png (deflated 13%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/R_curve.png (deflated 9%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/confusion_matrix.png (deflated 26%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/val_batch2_labels.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/P_curve.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/val_batch0_labels.jpg (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged36/val_batch0_pred.jpg (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged/args.yaml (deflated 53%)\n",
            "  adding: content/package_person_detection/yolov8m_merged/weights/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/confusion_matrix_normalized.png (deflated 22%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/results.csv (deflated 61%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/F1_curve.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/args.yaml (deflated 53%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best.onnx (deflated 17%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best.pt (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best.mlpackage/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best.mlpackage/Manifest.json (deflated 59%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best.mlpackage/Data/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best.mlpackage/Data/com.apple.CoreML/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best.mlpackage/Data/com.apple.CoreML/weights/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best.mlpackage/Data/com.apple.CoreML/weights/weight.bin (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best.mlpackage/Data/com.apple.CoreML/model.mlmodel (deflated 89%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best.engine (deflated 10%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best_saved_model/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best_saved_model/variables/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best_saved_model/variables/variables.data-00000-of-00001 (deflated 86%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best_saved_model/variables/variables.index (deflated 33%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best_saved_model/metadata.yaml (deflated 37%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best_saved_model/saved_model.pb (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best_saved_model/best_float16.tflite (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best_saved_model/assets/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best_saved_model/fingerprint.pb (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/best_saved_model/best_float32.tflite (deflated 17%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/weights/last.pt (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/results.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/train_batch0.jpg (deflated 6%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/train_batch1.jpg (deflated 3%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/val_batch1_labels.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/val_batch2_pred.jpg (deflated 6%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/labels.jpg (deflated 20%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/val_batch1_pred.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/PR_curve.png (deflated 13%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/R_curve.png (deflated 9%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/train_batch2.jpg (deflated 4%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/confusion_matrix.png (deflated 26%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/val_batch2_labels.jpg (deflated 6%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/labels_correlogram.jpg (deflated 35%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/P_curve.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/val_batch0_labels.jpg (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged3/val_batch0_pred.jpg (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/confusion_matrix_normalized.png (deflated 22%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/F1_curve.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/val_batch1_labels.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/val_batch2_pred.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/val_batch1_pred.jpg (deflated 6%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/PR_curve.png (deflated 13%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/R_curve.png (deflated 9%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/confusion_matrix.png (deflated 26%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/val_batch2_labels.jpg (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/P_curve.png (deflated 7%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/val_batch0_labels.jpg (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged33/val_batch0_pred.jpg (deflated 8%)\n",
            "  adding: content/package_person_detection/yolov8m_merged2/ (stored 0%)\n",
            "  adding: content/package_person_detection/yolov8m_merged2/args.yaml (deflated 53%)\n",
            "  adding: content/package_person_detection/yolov8m_merged2/weights/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/package_person_detection.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Uhda2yUDkhP1",
        "outputId": "1051d912-1a5d-4d6d-f354-a91b81913b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2d60ec78-4fc4-4213-8c61-d6d7ae079251\", \"package_person_detection.zip\", 606348627)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k3Hw0mIhGuO"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMZY2K/xZzO31QyZIq8mXPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}